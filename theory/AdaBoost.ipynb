{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1a9d84",
   "metadata": {},
   "source": [
    "### 基本思想\n",
    "\n",
    "#### “强可学习”，“弱可学习”\n",
    "\n",
    "- 强可学习：存在一个**多项式**的学习算法，并且学习到的策略正确率很高\n",
    "\n",
    "- 弱可学习：存在一个**多项式**的学习算法，并且学习到的策略正确率略好于随机策略\n",
    "\n",
    "- 有趣的事实：两者互为充要条件\n",
    "\n",
    "#### AdaBoost的简单理解\n",
    "\n",
    "AdaBoost通过训练几个弱分类器（在这里我们使用自己完成的决策树），并通过加法运算，最后得到一个强分类器。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7806ce0",
   "metadata": {},
   "source": [
    "### 训练过程\n",
    "\n",
    "输入：训练数据集 $T=\\{(x_1,y_1),...,(x_N,y_N)\\}$ 其中 $x_i$ 是n维实空间的一个点，$y_i$ 是-1或者1\n",
    "\n",
    "输出：最终分类器 $G(x)$ \n",
    "\n",
    "（2）初始化训练集的数据权重（一般来说是一个均匀分布，说明每个数据是同等重要的）\n",
    "\n",
    "$D_1=(w_{11},..,w_{1N}), w_{1i}=\\frac{1}{N}$ 在这里，w下标从左向右第一位表示第i个弱分类器，第二位表示第i个分类器中，第j个数据\n",
    "\n",
    "（2）遍历 $m=1,2,..,M$ 其中M是弱分类器的个数\n",
    "\n",
    "a. 使用 $D_m$ 作为数据集的训练权重，并得到基本分类器 $G_m(x): \\mathcal{X} \\to \\{-1,+1\\}$\n",
    "\n",
    "b. 计算使用 $G_m(x)$ 在数据集上的分类误差率 $e_m=\\sum_{i=1}^{N}P(G_m(x_i)\\neq y_i)=\\sum_{i=1}^{N}w_{mi}I(G_m(x_i) \\neq y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56392a8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
